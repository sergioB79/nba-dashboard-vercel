"""
getQuarters.py (vers√£o com GAME_ID normalizado + update incremental limpo)

- Cria / atualiza um ficheiro CSV com TODOS os jogos da √©poca 2025-26 (Regular Season),
  com pontos por per√≠odo (Q1..Q4) e total de OT (OT) por equipa, usando ScoreboardV3.
- Normaliza sempre GAME_ID para 10 d√≠gitos com zeros √† esquerda (ex: 0022500001).
- Se o ficheiro j√° existir, s√≥ chama a API para os jogos que ainda n√£o est√£o no CSV.
- No fim, mant√©m apenas os GAME_ID que aparecem no LeagueGameLog dessa √©poca (limpa lixo).
"""

import os
import time
from typing import Dict, List, Optional, Set

import pandas as pd
from nba_api.stats.endpoints import leaguegamelog, scoreboardv3

# ==============================
#  CONFIG
# ==============================

SEASON = "2025-26"               # √©poca atual
SEASON_TYPE = "Regular Season"   # ou "Playoffs"
OUTPUT_FILE = os.path.join("data", f"nba_quarters_{SEASON.replace('-', '')}.csv")
SLEEP_SECONDS = 0.8              # pausa entre chamadas √† API (ajusta se precisares)


# ==============================
#  HELPERS
# ==============================

def normalize_game_id(x) -> str:
    """
    Converte GAME_ID para string com 10 d√≠gitos, com zeros √† esquerda.
    Ex:
      22500001      -> '0022500001'
      '0022500001'  -> '0022500001'
      2.2500001e7   -> '0022500001'
    """
    s = "".join(ch for ch in str(x) if ch.isdigit())
    return s.zfill(10)


def safe_int(val) -> int:
    try:
        return int(val)
    except Exception:
        return 0


def get_season_games(season: str, season_type: str) -> pd.DataFrame:
    """
    Vai buscar todos os jogos da √©poca via LeagueGameLog (uma linha por equipa),
    depois reduz para uma linha por GAME_ID.
    """
    print(f"üìù A obter jogos da √©poca {season} ({season_type}) via LeagueGameLog...")
    lg = leaguegamelog.LeagueGameLog(
        season=season,
        season_type_all_star=season_type,
    )
    df = lg.get_data_frames()[0]

    games = (
        df[["GAME_ID", "GAME_DATE", "MATCHUP"]]
        .drop_duplicates("GAME_ID")
        .copy()
    )

    # Normalizar GAME_ID aqui logo
    games["GAME_ID"] = games["GAME_ID"].apply(normalize_game_id)

    # GAME_DATE como datetime + coluna s√≥ com date para agrupar por dia
    games["GAME_DATE"] = pd.to_datetime(games["GAME_DATE"])
    games["GAME_DAY"] = games["GAME_DATE"].dt.date

    print(f"‚úÖ Encontrados {len(games)} jogos √∫nicos nesta √©poca (LeagueGameLog).")
    return games


def fetch_day_from_scoreboard(game_day, request_timeout: int = 8) -> List[Dict]:
    """
    Usa ScoreboardV3 para um dia espec√≠fico e devolve linhas
    com Q1..Q4 + OT por equipa.
    """
    day_str = game_day.strftime("%Y-%m-%d")
    try:
        sb = scoreboardv3.ScoreboardV3(game_date=day_str, timeout=request_timeout)
        data = sb.get_dict()
        games = data.get("scoreboard", {}).get("games", [])
    except Exception as e:
        print(f"  ‚ö†Ô∏è Falha no ScoreboardV3 para {day_str}: {e}")
        return []

    rows: List[Dict] = []

    for g in games:
        game_id_raw = g.get("gameId")
        if not game_id_raw:
            continue
        game_id = normalize_game_id(game_id_raw)

        # home / away
        for side in ["homeTeam", "awayTeam"]:
            t = g.get(side, {}) or {}
            periods = t.get("periods", []) or []

            if not periods:
                continue

            # primeiros 4 per√≠odos = Q1..Q4
            q_scores = [safe_int(p.get("score")) for p in periods[:4]]
            while len(q_scores) < 4:
                q_scores.append(0)

            total = safe_int(t.get("score"))
            ot_total = max(0, total - sum(q_scores))

            try:
                team_id = int(t.get("teamId"))
            except Exception:
                continue

            rows.append(
                {
                    "GAME_ID": game_id,
                    "TEAM_ID": team_id,
                    "TEAM_ABBREVIATION": t.get("teamTricode") or "",
                    "TEAM_NAME": t.get("teamName") or "",
                    "Q1": q_scores[0],
                    "Q2": q_scores[1],
                    "Q3": q_scores[2],
                    "Q4": q_scores[3],
                    "OT": ot_total,
                    "OT_FLAG": 1 if len(periods) > 4 else 0,
                    "OT_PERIODS": max(0, len(periods) - 4),
                    "PTS": total,
                }
            )

    return rows


def load_existing_output(path: str) -> Optional[pd.DataFrame]:
    """
    L√™ o CSV existente (se houver). Se n√£o existir, devolve None.
    """
    if not os.path.exists(path):
        print("‚ÑπÔ∏è Ficheiro de sa√≠da ainda n√£o existe. Vai ser criado de raiz.")
        return None

    try:
        df = pd.read_csv(path)
        print(f"üìÇ Ficheiro existente encontrado: {path} (linhas: {len(df)})")
        return df
    except Exception as e:
        print(f"‚ö†Ô∏è Erro a ler ficheiro existente ({path}): {e}")
        print("   Vai ser ignorado e recriado de raiz.")
        return None


def get_existing_game_ids(existing: Optional[pd.DataFrame]) -> Set[str]:
    """
    Devolve o conjunto de GAME_ID j√° presentes no CSV para esta SEASON.
    Se n√£o houver ficheiro, devolve conjunto vazio.
    IMPORTANTE: assume GAME_ID j√° normalizado (normalize_game_id).
    """
    if existing is None:
        return set()

    if "GAME_ID" not in existing.columns:
        return set()

    # Se tiver coluna SEASON, filtramos s√≥ essa √©poca; se n√£o, usamos todos.
    if "SEASON" in existing.columns:
        mask = existing["SEASON"].astype(str) == SEASON
        ids = existing.loc[mask, "GAME_ID"].astype(str).unique()
    else:
        ids = existing["GAME_ID"].astype(str).unique()

    existing_ids = set(ids)
    print(f"üìå GAME_ID j√° existentes para {SEASON}: {len(existing_ids)}")
    return existing_ids


def cleanup_and_write(full_df: pd.DataFrame, games_df: pd.DataFrame) -> None:
    """
    - Normaliza GAME_ID no full_df
    - Remove jogos cujo GAME_ID n√£o est√° em games_df (garante s√≥ Regular Season 2025-26)
    - Remove duplicados (GAME_ID + TEAM_ID)
    - Ordena e grava o CSV final.
    """
    if full_df is None or full_df.empty:
        print("‚ùå Nada para gravar (full_df vazio).")
        return

    # Normalizar GAME_ID
    full_df = full_df.copy()
    full_df["GAME_ID"] = full_df["GAME_ID"].apply(normalize_game_id)

    # Conjunto de GAME_ID v√°lidos para esta √©poca (j√° normalizados em get_season_games)
    allowed_ids = set(games_df["GAME_ID"].astype(str).unique())

    before_filter = len(full_df)
    full_df = full_df[full_df["GAME_ID"].isin(allowed_ids)]
    after_filter = len(full_df)
    removed_lixo = before_filter - after_filter
    if removed_lixo > 0:
        print(f"üßπ Removidos {removed_lixo} registos cujo GAME_ID n√£o pertence √† √©poca {SEASON}.")

    # TEAM_ID como int se existir
    if "TEAM_ID" in full_df.columns:
        full_df["TEAM_ID"] = full_df["TEAM_ID"].apply(safe_int)

    # Remover duplicados por GAME_ID + TEAM_ID
    if {"GAME_ID", "TEAM_ID"}.issubset(full_df.columns):
        before_dups = len(full_df)
        full_df = full_df.drop_duplicates(subset=["GAME_ID", "TEAM_ID"], keep="last")
        after_dups = len(full_df)
        removed_dups = before_dups - after_dups
        if removed_dups > 0:
            print(f"üßπ Removidos {removed_dups} registos duplicados (GAME_ID+TEAM_ID).")

    # Ordenar e gravar
    sort_cols = [c for c in ["GAME_DATE", "GAME_ID", "TEAM_ID"] if c in full_df.columns]
    if sort_cols:
        full_df = full_df.sort_values(sort_cols).reset_index(drop=True)

    full_df.to_csv(OUTPUT_FILE, index=False, encoding="utf-8-sig")
    print(f"\n‚úÖ Ficheiro atualizado em: {OUTPUT_FILE}")
    print(f"   Linhas (equipa/jogo): {len(full_df)}")
    print("   Jogos √∫nicos (GAME_ID):", full_df["GAME_ID"].nunique())
    print("   Colunas:", ", ".join(full_df.columns))


# ==============================
#  MAIN
# ==============================

def main():
    # 1) Ler ficheiro existente (se houver)
    existing_df = load_existing_output(OUTPUT_FILE)
    if existing_df is not None and not existing_df.empty:
        # Normalizar GAME_ID imediatamente
        existing_df["GAME_ID"] = existing_df["GAME_ID"].apply(normalize_game_id)

    # 2) Jogos da √©poca (todos) via LeagueGameLog
    games_df = get_season_games(SEASON, SEASON_TYPE)
    if games_df.empty:
        print("‚ùå LeagueGameLog devolveu vazio. Nada para fazer.")
        return

    all_game_ids = set(games_df["GAME_ID"].astype(str).unique())

    # 3) Quais s√£o os jogos j√° existentes no CSV?
    existing_ids = get_existing_game_ids(existing_df)

    # 4) Quais s√£o os jogos em falta?
    missing_ids = all_game_ids - existing_ids
    print(f"üîç Jogos em falta nesta √©poca (ainda n√£o no CSV): {len(missing_ids)}")

    # 5) Se n√£o h√° jogos em falta, ainda assim limpamos/normalizamos e regravamos
    if len(missing_ids) == 0:
        if existing_df is None or existing_df.empty:
            print("‚ùå N√£o h√° ficheiro existente e n√£o h√° missing_ids (situa√ß√£o estranha).")
            return
        print("‚úÖ N√£o h√° jogos novos para adicionar. A limpar/normalizar ficheiro existente...")
        cleanup_and_write(existing_df, games_df)
        return

    # 6) Restringir o DataFrame de jogos apenas aos missing_ids
    games_missing_df = games_df[games_df["GAME_ID"].astype(str).isin(missing_ids)].copy()

    # Mapa r√°pido GAME_ID -> (GAME_DATE, MATCHUP)
    game_meta = (
        games_df[["GAME_ID", "GAME_DATE", "MATCHUP"]]
        .drop_duplicates("GAME_ID")
        .set_index("GAME_ID")
        .to_dict(orient="index")
    )

    # Lista de dias com jogos em falta
    days = sorted(games_missing_df["GAME_DAY"].unique())
    print(f"üìÖ N√∫mero de dias com jogos em falta: {len(days)}")

    all_rows: List[Dict] = []

    for idx, d in enumerate(days, start=1):
        print(f"[{idx}/{len(days)}] {d} ‚Üí a ler ScoreboardV3...")
        day_rows = fetch_day_from_scoreboard(d)
        if not day_rows:
            continue

        # Enriquecer com GAME_DATE / MATCHUP vindos do LeagueGameLog
        for r in day_rows:
            gid = str(r["GAME_ID"])
            # s√≥ queremos guardar se este jogo estiver em missing_ids
            if gid not in missing_ids:
                continue

            meta = game_meta.get(gid)
            if meta:
                # meta["GAME_DATE"] √© datetime (porque convertida em get_season_games)
                r["GAME_DATE"] = meta["GAME_DATE"].strftime("%Y-%m-%d")
                r["MATCHUP"] = meta["MATCHUP"]
            else:
                # fallback se algum GAME_ID n√£o estiver em LeagueGameLog
                r["GAME_DATE"] = d.strftime("%Y-%m-%d")
                r["MATCHUP"] = ""

            r["SEASON"] = SEASON
            r["SEASON_TYPE"] = SEASON_TYPE

            all_rows.append(r)

        time.sleep(SLEEP_SECONDS)

    if not all_rows:
        print("‚ùå Scoreboard n√£o devolveu dados novos para nenhum dia (jogos podem ainda n√£o ter boxscore dispon√≠vel).")
        # Mesmo assim limpamos/normalizamos o que j√° existe
        if existing_df is not None and not existing_df.empty:
            cleanup_and_write(existing_df, games_df)
        return

    new_df = pd.DataFrame(all_rows)
    print(f"‚ûï Novas linhas obtidas (equipa/jogo): {len(new_df)}")

    # 7) Juntar com dados antigos (se existirem)
    if existing_df is not None and not existing_df.empty:
        full_df = pd.concat([existing_df, new_df], ignore_index=True)
    else:
        full_df = new_df

    # 8) Limpar, normalizar e gravar ficheiro final
    cleanup_and_write(full_df, games_df)


if __name__ == "__main__":
    main()
